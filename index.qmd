---
title: 'Bias-reduced estimation of structural equation models'
# subtitle: A statistical perspective
format:
  kaust-revealjs:
    slide-level: 2
    transition: fade
    auto-stretch: false
    width: 1250  # 1050
    height: 760  # 700
    self-contained: false
    chalkboard: true
    toc: false
    toc-depth: 1
    # multiplex: true
    code-block-height: 700px
    # html-table-processing: none
author:
  - name: Haziq Jamil
    orcid: 0000-0003-3298-1010
    affiliations: 
      - 'Research Specialist, BAYESCOMP @ CEMSE-KAUST'
      - '<span style="font-style:normal;">[`https://haziqj.ml/sem-bias/`](https://haziqj.ml/sem-bias/)</span>'
date: 2025-10-16
bibliography: refs.bib
execute:
  echo: false
  freeze: auto
  cache: true
---

## 

::: {.columns}

::: {.column width="33%"}
<figure class="quarto-figure quarto-figure-center" style="text-align:center;">
  <a href="https://lavaan.org" target="_blank">
    <img
      src="https://science-academy.ugent.be/sites/acugain/files/styles/medium_1_1/public/teachers/rosseel_yves.jpg?h=04d92ac6&itok=GUYp9IIm"
      alt="Yves Rosseel"
      style="--size:220px; width:var(--size); height:var(--size);
             object-fit:cover; object-position:top;"
    >
  </a>
  <figcaption>
    Yves Rosseel<br><em>Universiteit Gent</em> | R/<code>{lavaan}</code>
  </figcaption>
</figure>
:::

::: {.column width="33%"}
<figure class="quarto-figure quarto-figure-center" style="text-align:center;">
  <img
    src="https://warwick.ac.uk/fac/sci/statistics/staff/research_students/kemp/img_warwick.jpg"
    style="--size:220px; width:var(--size); height:var(--size);
           object-fit:cover; object-position:top;"
  >
  <figcaption>Ollie Kemp<br><em>University of Warwick</em></figcaption>
</figure>
:::

::: {.column width="33%"}
<figure class="quarto-figure quarto-figure-center" style="text-align:center;">
  <a href="https://www.ikosmidis.com" target="_blank">
    <img
      src="https://www.ikosmidis.com/img/me.jpg"
      style="--size:220px; width:var(--size); height:var(--size);
             object-fit:cover; object-position:top;"
    >
  </a>
  <figcaption>Ioannis Kosmidis<br><em>University of Warwick</em></figcaption>
</figure>
:::

:::

::: {.nudge-up}

> **Jamil, H.**, Rosseel, Y., Kemp, O., & Kosmidis, I. (2025). Bias-Reduced Estimation of Structural Equation Models. *Manuscript in Submission*. [`arXiv:2509.25419`](https://doi.org/10.48550/arXiv.2509.25419).

- Source: <https://github.com/haziqj/sembias-gradsem>
- R Package: <https://github.com/haziqj/brlavaan>

:::

[{{< placeholder 220 220 format=svg >}}]{.absolute bottom=10 right=0}

[[**poll**]{.bg-grn}]{.absolute bottom=220 right=235}

## Context

::: {.callout-note icon=false title="SEM in a nutshell"}
Analyse multivariate data $\mathbf y=(y_1,\dots,y_p)^\top$ to measure and relate hidden variables $\boldsymbol\eta=(\eta_1,\dots,\eta_q)^\top$, $q \ll p$, and uncover complex patterns.
:::

::: {.nudge-up-small}
In the social sciences, latent variables are used to represent **constructs**---the *theoretical, unobserved* concepts of interest.
:::

::: {.nudge-up}
:::: {.columns}

::: {.column width="25%"}
![*(Psychology)*<br>Personality traits](https://unsplash.com/photos/5bYxXawHOQg/download?ixid=M3wxMjA3fDB8MXxhbGx8fHx8fHx8fHwxNzU5MjMzMTM4fA&force=true&w=640){height=210px}
:::

::: {.column width="25%"}
![*(Healthcare)*<br>Quality of life](https://unsplash.com/photos/hIgeoQjS_iE/download?ixid=M3wxMjA3fDB8MXxhbGx8fHx8fHx8fHwxNzU5MjI2Nzg4fA&force=true&w=640){height=210px}
:::

::: {.column width="25%"}
![*(Political science)*<br>Social trust](https://unsplash.com/photos/zjeZXMU1SKE/download?ixid=M3wxMjA3fDB8MXxhbGx8fHx8fHx8fHwxNzU5MjMzNzIxfA&force=true&w=640){height=210px}
:::

::: {.column width="25%"}
![*(Education)*<br>Competencies](https://unsplash.com/photos/oXV3bzR7jxI/download?ixid=M3wxMjA3fDB8MXxhbGx8fHx8fHx8fHwxNzU5MjMzNzM1fA&force=true&w=640){height=210px}
:::

::::
:::

::: {.aside}
Photo credits: Unsplash
[\@dtravisphd](https://unsplash.com/photos/brown-fountain-pen-on-notebook-5bYxXawHOQg),
[\@impulsq](https://unsplash.com/photos/doctor-holding-red-stethoscope-hIgeoQjS_iE),
[\@ev](https://unsplash.com/photos/a-group-of-police-standing-next-to-each-other-zjeZXMU1SKE),
[\@benmullins](https://unsplash.com/photos/person-using-pencil-oXV3bzR7jxI).
:::

## Motivation

*"Using SEMs in empirical research is often challenged by small sample sizes."*

- Why? Data collection is expensive, time-consuming, or difficult.
- Rare populations:
    - **@quezada2016explanatory:** Identifying factors of adjustment in pediatric burn patients to facilitate appropriate mental health interventions postinjury ($n=51$).
    - **@figueroa2021structural:** Studying functional connectivity network on individuals with rare genetic disorders ($n=22$).
    - **@fabbricatore2023componentbased**: Assessment of psycho-social aspects and performance of elite swimmers ($n=161$).
    - **@manuela2013pacific**: Validating self-report measures of identity on a unique cultural group ($n=143$).
- SEM is desirable, but small $n \Rightarrow$ poor finite-sample performance (esp. bias). 

## Outline

1. Brief overview of SEMs
    - Model equations
    - ML estimation and inference
    - Examples of SEMs
      - Two-factor SEM
      - Latent growth models
2. Bias reducing methods
    - A review
    - Resampling-based methods
    - Alternative approaches
    - Reduced-Bias $M$-estimation (RBM)
3. Simulation studies and results

# Structural equation models {.transition-slide}

## Measurement model

## Structural model

## Example 1: Political democracy example

## ML estimation

## Properties of MLE

Let $\bar{\vartheta}$ be the true parameter value.
Subject to standard regularity conditions [@cox1979theoretical], as $n\to\infty$,

$$
\sqrt n (\hat\vartheta - \bar\vartheta) \xrightarrow{\;\;\text D\;\;} 
\begin{cases}
\text N_m\left(\mathbf 0, \big[ U(\bar\vartheta)V(\bar\vartheta)^{-1} U(\bar\vartheta) \big]^{-1} \right) &\text{model misspecified} \\
\text{N}_m\big(\mathbf 0, I(\bar\vartheta)^{-1} \big) &\text{otherwise}
\end{cases}
$$
where

- $I(\vartheta) = \mathbb{E}\left[ \nabla\ell_1(\vartheta)\nabla\ell_1(\vartheta)^\top \right]$ is the *Fisher information*;
- $U(\vartheta) = -\mathbb{E}\left[ \nabla\nabla^\top \ell_1(\vartheta) \right]$ is the *sensitivity matrix*; and
- $V(\vartheta) = \mathbb{E}\left[ \nabla\ell_1(\vartheta)\nabla\ell_1(\vartheta)^\top \right]$ is the *variability matrix*.

::: {.nudge-up}
Calculation of SEs are based off estimates of these matrices.
The "sandwich" matrix gives robust SEs [@satorra1994corrections;@savalei2014understanding].
:::


## Example 2: Latent growth curve model

## REML

# Bias reduction methods {.transition-slide}

## What is bias?

::: {.callout-tip icon=false}
#### Bias of an estimator
$$
\mathcal B_{\bar\vartheta}(\hat\vartheta) = \mathbb E\left[\hat\vartheta - \bar\vartheta\right] 
$${#eq-bias}
:::

Consider the stochastic Taylor expansion of $s(\hat\vartheta)=\nabla\ell(\vartheta)=0$ around $\bar\vartheta$.
For many common estimators including MLE, the bias function is:
$$
\mathcal B_{\bar\vartheta} = \frac{b_1(\bar\vartheta)}{n} +  \frac{b_2(\bar\vartheta)}{n^2} + \frac{b_3(\bar\vartheta)}{n^3} +O(n^{-4}).
$$

::: {.nudge-up}
Bias arises because the roots of the score equations are **not exactly centred at $\bar\vartheta$**, due to:

a. The curvature of the score $s(\vartheta)$; and
b. The randomness of the score itself.
:::

## Illustration

### Biased MLE estimator for $\sigma^2$ 

Consider $X_1,\dots,X_n \sim \text N(0, \sigma^2)$. The MLE for $\sigma^2$ is $\hat\sigma^2 = \frac{1}{n}\sum_{i=1}^n X_i^2$.

## Illustration (cont.)

What's happening to the score functions?

## Adjusting score equations


## If you're interested... 

### ...and love differentiation Ô∏è‚ù§Ô∏èü§ì

For a comprehensive treatment of bias-reduction methods,

- Start here: @cox1968general
- Follow up with: @firth1993bias; @kosmidis2009bias; @kosmidis2014bias


::: {.fragment}
::: {.nudge-up}
By the way, the $O(n^{-1})$ bias term $b_1(\bar\vartheta)/n = -I(\bar\vartheta)^{-1} C(\bar\vartheta)$, where
$$
\begin{gathered}
C_a(\vartheta) = \frac{1}{2} \operatorname{tr} \left[
I(\vartheta)^{-1}\big( G_a(\vartheta) + H_a(\vartheta) \big)
\right]\\ 
G_a(\vartheta)=\mathbb E[s(\vartheta)s(\vartheta)^\top s_a(\vartheta)] 
\quad\quad 
H_a(\vartheta)=-\mathbb E[I(\vartheta)s_a(\vartheta)] \\
a=1,\dots,m
\end{gathered}
$$
where $s(\vartheta) = \nabla\ell(\vartheta)$ is the score function.
:::
:::

## A review

## Firth's adjusted scores methods

## RBM framework

## Resampling-based methods

# Simulation Studies {.transition-slide}

## Simulation design

## Results: Two-factor SEM 

## Results: Latent GCM

# Summary {.transition-slide}

# ÿ¥ŸÉÿ±ÿßŸã ÿ¨ÿ≤ŸäŸÑÿßŸã {.thanks-slide  background-image="_extensions/haziqj/kaust/KAUST-Thank-you.jpg" style="padding-top:0.5em;padding-bottom:0em"}

[`https://haziqj.ml/sembias-gradsem`](https://haziqj.ml/sembias-gradsem)

## References