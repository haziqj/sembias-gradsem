{
  "hash": "70b710bec44e4bf6e6731710fb5d3eca",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: 'Bias-reduced estimation of structural equation models'\n# subtitle: A statistical perspective\nformat:\n  kaust-revealjs:\n    slide-level: 2\n    transition: fade\n    auto-stretch: false\n    width: 1250  # 1050\n    height: 760  # 700\n    self-contained: false\n    chalkboard: true\n    toc: false\n    toc-depth: 1\n    # multiplex: true\n    code-block-height: 700px\n    # html-table-processing: none\nauthor:\n  - name: Haziq Jamil\n    orcid: 0000-0003-3298-1010\n    affiliations: \n      - 'Research Specialist, BAYESCOMP @ CEMSE-KAUST'\n      - '<span style=\"font-style:normal;\">[`https://haziqj.ml/sem-bias/`](https://haziqj.ml/sem-bias/)</span>'\ndate: 2025-10-16\nbibliography: refs.bib\nexecute:\n  echo: false\n  freeze: auto\n  cache: false\n---\n\n## \n\n\n\n\n::: {.columns}\n\n::: {.column width=\"33%\"}\n<figure class=\"quarto-figure quarto-figure-center\" style=\"text-align:center;\">\n  <a href=\"https://lavaan.org\" target=\"_blank\">\n    <img\n      src=\"https://science-academy.ugent.be/sites/acugain/files/styles/medium_1_1/public/teachers/rosseel_yves.jpg?h=04d92ac6&itok=GUYp9IIm\"\n      alt=\"Yves Rosseel\"\n      style=\"--size:220px; width:var(--size); height:var(--size);\n             object-fit:cover; object-position:top;\"\n    >\n  </a>\n  <figcaption>\n    Yves Rosseel<br><em>Universiteit Gent</em> | R/<code>{lavaan}</code>\n  </figcaption>\n</figure>\n:::\n\n::: {.column width=\"33%\"}\n<figure class=\"quarto-figure quarto-figure-center\" style=\"text-align:center;\">\n  <img\n    src=\"https://warwick.ac.uk/fac/sci/statistics/staff/research_students/kemp/img_warwick.jpg\"\n    style=\"--size:220px; width:var(--size); height:var(--size);\n           object-fit:cover; object-position:top;\"\n  >\n  <figcaption>Ollie Kemp<br><em>University of Warwick</em></figcaption>\n</figure>\n:::\n\n::: {.column width=\"33%\"}\n<figure class=\"quarto-figure quarto-figure-center\" style=\"text-align:center;\">\n  <a href=\"https://www.ikosmidis.com\" target=\"_blank\">\n    <img\n      src=\"https://www.ikosmidis.com/img/me.jpg\"\n      style=\"--size:220px; width:var(--size); height:var(--size);\n             object-fit:cover; object-position:top;\"\n    >\n  </a>\n  <figcaption>Ioannis Kosmidis<br><em>University of Warwick</em></figcaption>\n</figure>\n:::\n\n:::\n\n::: {.nudge-up}\n\n> **Jamil, H.**, Rosseel, Y., Kemp, O., & Kosmidis, I. (2025). Bias-Reduced Estimation of Structural Equation Models. *Manuscript in Submission*. [`arXiv:2509.25419`](https://doi.org/10.48550/arXiv.2509.25419).\n\n- Source: <https://github.com/haziqj/sembias-gradsem>\n- R Package: <https://github.com/haziqj/brlavaan>\n\n:::\n\n[{{< placeholder 220 220 format=svg >}}]{.absolute bottom=10 right=0}\n\n[[**poll**]{.bg-grn}]{.absolute bottom=220 right=235}\n\n## Context\n\n::: {.callout-note icon=false title=\"SEM in a nutshell\"}\nAnalyse multivariate data $\\mathbf y=(y_1,\\dots,y_p)^\\top$ to measure and relate hidden variables $\\boldsymbol\\eta=(\\eta_1,\\dots,\\eta_q)^\\top$, $q \\ll p$, and uncover complex patterns.\n:::\n\n::: {.nudge-up-small}\nIn the social sciences, latent variables are used to represent **constructs**---the *theoretical, unobserved* concepts of interest.\n:::\n\n::: {.nudge-up}\n:::: {.columns}\n\n::: {.column width=\"25%\"}\n![*(Psychology)*<br>Personality traits](https://unsplash.com/photos/5bYxXawHOQg/download?ixid=M3wxMjA3fDB8MXxhbGx8fHx8fHx8fHwxNzU5MjMzMTM4fA&force=true&w=640){height=210px}\n:::\n\n::: {.column width=\"25%\"}\n![*(Healthcare)*<br>Quality of life](https://unsplash.com/photos/hIgeoQjS_iE/download?ixid=M3wxMjA3fDB8MXxhbGx8fHx8fHx8fHwxNzU5MjI2Nzg4fA&force=true&w=640){height=210px}\n:::\n\n::: {.column width=\"25%\"}\n![*(Political science)*<br>Social trust](https://unsplash.com/photos/zjeZXMU1SKE/download?ixid=M3wxMjA3fDB8MXxhbGx8fHx8fHx8fHwxNzU5MjMzNzIxfA&force=true&w=640){height=210px}\n:::\n\n::: {.column width=\"25%\"}\n![*(Education)*<br>Competencies](https://unsplash.com/photos/oXV3bzR7jxI/download?ixid=M3wxMjA3fDB8MXxhbGx8fHx8fHx8fHwxNzU5MjMzNzM1fA&force=true&w=640){height=210px}\n:::\n\n::::\n:::\n\n::: {.aside}\nPhoto credits: Unsplash\n[\\@dtravisphd](https://unsplash.com/photos/brown-fountain-pen-on-notebook-5bYxXawHOQg),\n[\\@impulsq](https://unsplash.com/photos/doctor-holding-red-stethoscope-hIgeoQjS_iE),\n[\\@ev](https://unsplash.com/photos/a-group-of-police-standing-next-to-each-other-zjeZXMU1SKE),\n[\\@benmullins](https://unsplash.com/photos/person-using-pencil-oXV3bzR7jxI).\n:::\n\n## Motivation\n\n*\"Using SEMs in empirical research is often challenged by small sample sizes.\"*\n\n- Why? Data collection is expensive, time-consuming, or difficult.\n- Rare populations:\n    - **@quezada2016explanatory:** Identifying factors of adjustment in pediatric burn patients to facilitate appropriate mental health interventions postinjury ($n=51$).\n    - **@figueroa2021structural:** Studying functional connectivity network on individuals with rare genetic disorders ($n=22$).\n    - **@fabbricatore2023componentbased**: Assessment of psycho-social aspects and performance of elite swimmers ($n=161$).\n    - **@manuela2013pacific**: Validating self-report measures of identity on a unique cultural group ($n=143$).\n- SEM is desirable, but small $n \\Rightarrow$ poor finite-sample performance (esp. bias). \n\n## Outline\n\n1. Brief overview of SEMs\n    - Model equations\n    - ML estimation and inference\n    - Examples of SEMs\n      - Two-factor SEM\n      - Latent growth models\n2. Bias reducing methods\n    - A review\n    - Resampling-based methods\n    - Alternative approaches\n    - Reduced-Bias $M$-estimation (RBM)\n3. Simulation studies and results\n\n# Structural equation models {.transition-slide}\n\n## Measurement model\n\n## Structural model\n\n## Example 1: Political democracy example\n\n## ML estimation\n\n## Properties of MLE\n\nLet $\\bar{\\vartheta}$ be the true parameter value.\nSubject to standard regularity conditions [@cox1979theoretical], as $n\\to\\infty$,\n\n$$\n\\sqrt n (\\hat\\vartheta - \\bar\\vartheta) \\xrightarrow{\\;\\;\\text D\\;\\;} \n\\begin{cases}\n\\text N_m\\left(\\mathbf 0, \\big[ U(\\bar\\vartheta)V(\\bar\\vartheta)^{-1} U(\\bar\\vartheta) \\big]^{-1} \\right) &\\text{model misspecified} \\\\\n\\text{N}_m\\big(\\mathbf 0, I(\\bar\\vartheta)^{-1} \\big) &\\text{otherwise}\n\\end{cases}\n$$\nwhere\n\n- $I(\\vartheta) = \\mathbb{E}\\left[ \\nabla\\ell_1(\\vartheta)\\nabla\\ell_1(\\vartheta)^\\top \\right]$ is the *Fisher information*;\n- $U(\\vartheta) = -\\mathbb{E}\\left[ \\nabla\\nabla^\\top \\ell_1(\\vartheta) \\right]$ is the *sensitivity matrix*; and\n- $V(\\vartheta) = \\mathbb{E}\\left[ \\nabla\\ell_1(\\vartheta)\\nabla\\ell_1(\\vartheta)^\\top \\right]$ is the *variability matrix*.\n\n::: {.nudge-up}\nCalculation of SEs are based off estimates of these matrices.\nThe \"sandwich\" matrix gives robust SEs [@satorra1994corrections;@savalei2014understanding].\n:::\n\n\n## Example 2: Latent growth curve model\n\n## REML\n\n# Bias reduction methods {.transition-slide}\n\n## What is bias?\n\n::: {.callout-tip icon=false}\n#### Bias of an estimator\n$$\n\\mathcal B_{\\bar\\vartheta}(\\hat\\vartheta) = \\mathbb E\\left[\\hat\\vartheta - \\bar\\vartheta\\right] \n$${#eq-bias}\n:::\n\n\n::: {.nudge-up}\nConsider the stochastic Taylor expansion of $s(\\hat\\vartheta)=\\nabla\\ell(\\vartheta)=0$ around $\\bar\\vartheta$.\nFor many common estimators including MLE, the bias function is:\n$$\n\\mathcal B_{\\bar\\vartheta} = \\frac{b_1(\\bar\\vartheta)}{n} +  \\frac{b_2(\\bar\\vartheta)}{n^2} + \\frac{b_3(\\bar\\vartheta)}{n^3} +O(n^{-4}).\n$$\n\n::: {.nudge-up}\nBias arises because the roots of the score equations are **not exactly centred at $\\bar\\vartheta$**, due to:\n\n::: {.nudge-up-small}\na. The curvature of the score $s(\\vartheta)$; and\nb. The randomness of the score itself.\n:::\n:::\n:::\n\n## Illustration\n\n### Biased MLE estimator for $\\sigma^2$ \n\nConsider $X_1,\\dots,X_n \\sim \\text N(0, \\sigma^2)$. The MLE for $\\sigma^2$ is $\\hat\\sigma^2 = \\frac{1}{n}\\sum_{i=1}^n X_i^2$.\n\n::: {.panel-tabset}\n\n### $n=10$\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-revealjs/unnamed-chunk-2-1.png){width=100%}\n:::\n:::\n\n\n### $n=25$\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-revealjs/unnamed-chunk-3-1.png){width=100%}\n:::\n:::\n\n\n### $n=1000$\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-revealjs/unnamed-chunk-4-1.png){width=100%}\n:::\n:::\n\n\n:::\n\n## Illustration (cont.)\n\n### Score functions are random too\n\n\n\n## If you're interested... \n\n### ...and love differentiation Ô∏è‚ù§Ô∏èü§ì\n\nFor a comprehensive treatment of bias-reduction methods,\n\n- Start here: @cox1968general\n- Follow up with: @firth1993bias; @kosmidis2009bias; @kosmidis2014bias\n\n\n::: {.fragment}\n::: {.nudge-up}\nBy the way, the $O(n^{-1})$ bias term $b_1(\\bar\\vartheta)/n = -I(\\bar\\vartheta)^{-1} C(\\bar\\vartheta)$, where\n$$\n\\begin{gathered}\nC_a(\\vartheta) = \\frac{1}{2} \\operatorname{tr} \\left[\nI(\\vartheta)^{-1}\\big( G_a(\\vartheta) + H_a(\\vartheta) \\big)\n\\right]\\\\ \nG_a(\\vartheta)=\\mathbb E[s(\\vartheta)s(\\vartheta)^\\top s_a(\\vartheta)] \n\\quad\\quad \nH_a(\\vartheta)=-\\mathbb E[I(\\vartheta)s_a(\\vartheta)] \\\\\na=1,\\dots,m\n\\end{gathered}\n$$\nwhere $s(\\vartheta) = \\nabla\\ell(\\vartheta)$ is the score function.\n:::\n:::\n\n## A review\n\n## Firth's adjusted scores methods\n\n## RBM framework\n\n## Resampling-based methods\n\n# Simulation Studies {.transition-slide}\n\n## Simulation design\n\n## Results: Two-factor SEM \n\n## Results: Latent GCM\n\n# Conclusion {.transition-slide}\n\n## Summary & future work\n\n## Software\n\n\n# ÿ¥ŸÉÿ±ÿßŸã ÿ¨ÿ≤ŸäŸÑÿßŸã {.thanks-slide  background-image=\"_extensions/haziqj/kaust/KAUST-Thank-you.jpg\" style=\"padding-top:0.5em;padding-bottom:0em\"}\n\n[`https://haziqj.ml/sembias-gradsem`](https://haziqj.ml/sembias-gradsem)\n\n## References",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}